#!/usr/bin/env python3
"""
===========================
PyMakeOneFile - File Combiner
===========================

SYNOPSIS
========
Combines the content of multiple text files from a specified directory and its 
subdirectories into a single output file. Each file's content is preceded by 
a separator showing metadata such as the file path, modification date, size, 
and type.

DESCRIPTION
===========
This script is a Python alternative to the PowerShell `makeonefile.ps1` script.
It's designed to help consolidate multiple source code files or text documents 
into a single file, which can be useful for:

- Code reviews (though dedicated review tools are often better for large projects).
- Creating a single document bundle for sharing or archiving.
- Simple documentation generation by concatenating markdown files.

KEY FEATURES
============
- Recursive file scanning in a source directory.
- Customizable separators between file contents ('Standard', 'Detailed', 'Markdown').
- Option to add a timestamp to the output filename.
- Exclusion of common project directories (e.g., 'node_modules', '.git', 'build').
- Exclusion of binary files by default (based on extension).
- Option to include dot-files (e.g., '.gitignore') and binary files.
- Case-insensitive exclusion of additional specified directory names.
- Control over line endings (LF or CRLF) for script-generated separators.
- Verbose mode for detailed logging.
- Prompts for overwriting an existing output file unless `--force` is used.

REQUIREMENTS
============
- Python 3.7+ (due to `pathlib` usage and f-strings; `Path.resolve(strict=True)` needs 3.6+)
- Standard Python libraries only (argparse, datetime, logging, os, pathlib, shutil, sys).

INSTALLATION
============
No special installation is needed. Just download the script (`pymakeonefile.py`) 
and ensure it has execute permissions if you want to run it directly 
(e.g., `chmod +x pymakeonefile.py` on Linux/macOS).

USAGE
=====
Basic command:
  python pymakeonefile.py --source-directory /path/to/your/code --output-file /path/to/combined_output.txt

With more options:
  python pymakeonefile.py -s ./my_project -o ./output/bundle.md -t --separator-style Markdown --force --verbose --additional-excludes "temp" "docs_old"

For all options, run:
  python pymakeonefile.py --help

NOTES
=====
- Binary Files: While the script can attempt to include binary files using the 
  `--include-binary-files` flag, the content will be read as text (UTF-8 with 
  error ignoring). This can result in garbled/unreadable content in the output 
  and significantly increase file size. This feature is generally for including 
  files that might be misidentified as binary or for specific edge cases.
- Performance: For extremely large directories with tens of thousands of files or 
  very large individual files, the script might take some time to process.
- Encoding: The script attempts to read files as UTF-8 and writes the output file 
  as UTF-8. Files with other encodings might not be handled perfectly, especially 
  if they contain characters not representable in UTF-8 or if `errors='ignore'` 
  has to discard characters.
- Line Endings of Source Files: The script preserves the original line endings of 
  the content from the source files. The `--line-ending` option only affects the 
  separators and blank lines *generated by this script*.

AUTHOR
======
Franz und Franz (Original PowerShell script)
AI (Python conversion and enhancements)

VERSION
=======
1.1.0 (Python Version)
"""

import argparse
import datetime
import logging
import os
import sys
from pathlib import Path

# --- Logger Setup ---
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO, format='%(levelname)-8s: %(message)s')

# --- Global Definitions ---

DEFAULT_EXCLUDED_DIR_NAMES = [
    'vendor',
    'node_modules',
    'build',
    'dist',
    'cache',
    '.git',      # Explicitly add common VCS directories
    '.svn',
    '.hg',
    '__pycache__',
]

BINARY_FILE_EXTENSIONS = {
    # Images
    '.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff', '.tif', '.ico', '.webp', '.svgz',
    # Audio
    '.mp3', '.wav', '.ogg', '.flac', '.aac', '.wma', '.m4a',
    # Video
    '.mp4', '.avi', '.mkv', '.mov', '.wmv', '.flv', '.webm', '.mpeg', '.mpg',
    # Executables and compiled code
    '.exe', '.dll', '.so', '.dylib', '.bin', '.msi', '.pdb', '.lib', '.o', '.obj', '.pyc', '.pyo', '.class',
    # Archives
    '.zip', '.rar', '.7z', '.tar', '.gz', '.bz2', '.xz', '.jar', '.war', '.ear', '.cab',
    # Binary documents
    '.pdf', '.doc', '.ppt', # Note: .docx, .xlsx, .pptx are XML-based (zip archives)
    # Databases & Data Files
    '.db', '.sqlite', '.mdb', '.accdb', '.dbf', '.dat', # .dat is generic
    # Fonts
    '.ttf', '.otf', '.woff', '.woff2', '.eot',
    # Proprietary design formats
    '.psd', '.ai', '.indd', '.xd', '.fig',
    # Virtualization & Disk Images
    '.iso', '.img', '.vhd', '.vhdx', '.vmdk',
    # Other common binary types
    '.bak', '.tmp', '.lock', '.swo', '.swp'
}

# Line Ending Constants
LF = '\n'
CRLF = '\r\n'

# --- Helper Functions ---

def get_file_size_formatted(size_in_bytes: int) -> str:
    """Formats file size into a human-readable string (Bytes, KB, MB)."""
    if size_in_bytes < 1024:
        return f"{size_in_bytes} Bytes"
    elif size_in_bytes < (1024 * 1024):  # Less than 1 MB
        return f"{size_in_bytes / 1024:.2f} KB"
    else:  # 1 MB or more
        return f"{size_in_bytes / (1024 * 1024):.2f} MB"

def get_file_separator(file_info: Path, relative_path: str, style: str, linesep: str) -> str:
    """
    Generates the file separator string based on the chosen style.

    Args:
        file_info: Path object for the file.
        relative_path: Relative path string of the file from the source directory.
        style: The separator style ('Standard', 'Detailed', 'Markdown').
        linesep: The line separator string (LF or CRLF) to use.

    Returns:
        The formatted separator string.
    """
    stat_info = file_info.stat()
    mod_time = datetime.datetime.fromtimestamp(stat_info.st_mtime)
    mod_date_str = mod_time.strftime('%Y-%m-%d %H:%M:%S')
    file_size_str = get_file_size_formatted(stat_info.st_size)
    file_ext = file_info.suffix.lower() if file_info.suffix else "[no extension]"

    if style == 'Standard':
        return f"======= {relative_path} ======="
    elif style == 'Detailed':
        separator_lines = [
            "========================================================================================",
            f"== FILE: {relative_path}",
            f"== DATE: {mod_date_str} | SIZE: {file_size_str} | TYPE: {file_ext}",
            "========================================================================================"
        ]
        return linesep.join(separator_lines)
    elif style == 'Markdown':
        md_lang_hint = file_info.suffix[1:] if file_info.suffix and len(file_info.suffix) > 1 else ""
        separator_lines = [
            f"## {relative_path}",
            f"**Date Modified:** {mod_date_str} | **Size:** {file_size_str} | **Type:** {file_ext}",
            "", # Empty line before code block
            f"```{md_lang_hint}"
        ]
        return linesep.join(separator_lines)
    else: # Should not happen due to argparse choices
        logger.warning(f"Unknown separator style '{style}'. Falling back to basic.")
        return f"--- {relative_path} ---"

def get_closing_separator(style: str) -> str | None:
    """
    Generates the closing separator string, if any.

    Args:
        style: The separator style.

    Returns:
        The closing separator string, or None if no closing separator is needed.
    """
    if style == 'Markdown':
        return "```"
    return None

# --- Refactored Helper Functions for main() ---

def _configure_logging_settings(verbose: bool, chosen_linesep: str) -> None:
    """Configures logging level based on verbosity."""
    if verbose:
        logging.getLogger().setLevel(logging.DEBUG)
        logger.debug("Verbose mode enabled.")
        logger.debug(f"Using line ending: {'LF' if chosen_linesep == LF else 'CRLF'}")

def _resolve_and_validate_source_path(source_directory_str: str) -> Path:
    """Resolves and validates the source directory path."""
    try:
        source_dir = Path(source_directory_str).resolve(strict=True)
        if not source_dir.is_dir():
            logger.error(f"Source path '{source_dir}' is not a directory.")
            sys.exit(1)
        return source_dir
    except FileNotFoundError:
        logger.error(f"Source directory '{source_directory_str}' not found.")
        sys.exit(1)
    except Exception as e:
        logger.error(f"Error resolving source directory '{source_directory_str}': {e}")
        sys.exit(1)

def _prepare_output_file_path(output_file_str: str, add_timestamp: bool) -> Path:
    """Prepares the output file path, including timestamp if requested."""
    output_file_path = Path(output_file_str).resolve()
    if add_timestamp:
        timestamp = datetime.datetime.now().strftime("_%Y%m%d_%H%M%S")
        output_file_path = output_file_path.with_name(
            f"{output_file_path.stem}{timestamp}{output_file_path.suffix}"
        )
        logger.debug(f"Output filename with timestamp: {output_file_path.name}")
    return output_file_path

def _handle_output_file_overwrite_and_creation(output_file_path: Path, force: bool, chosen_linesep: str) -> None:
    """Handles output file existence, overwrite confirmation, and parent directory creation."""
    if output_file_path.exists() and output_file_path.is_file():
        if force:
            logger.warning(f"Output file '{output_file_path}' exists. Overwriting due to --force.")
            try:
                output_file_path.unlink()
            except Exception as e:
                logger.error(f"Could not remove existing output file '{output_file_path}': {e}")
                sys.exit(1)
        else:
            try:
                confirmation = input(f"Output file '{output_file_path}' already exists. Overwrite? (y/N): ")
                if confirmation.lower() != 'y':
                    logger.info("Operation cancelled by user.")
                    sys.exit(0)
                output_file_path.unlink()
                logger.debug(f"Overwriting existing output file '{output_file_path}'.")
            except KeyboardInterrupt:
                logger.info(f"{chosen_linesep}Operation cancelled by user (Ctrl+C).")
                sys.exit(0)
            except Exception as e:
                logger.error(f"Could not remove existing output file '{output_file_path}': {e}")
                sys.exit(1)
    elif output_file_path.exists() and not output_file_path.is_file():
        logger.error(f"Output path '{output_file_path}' exists but is not a file (e.g., it's a directory).")
        sys.exit(1)

    try:
        output_file_path.parent.mkdir(parents=True, exist_ok=True)
    except Exception as e:
        logger.error(f"Could not create output directory '{output_file_path.parent}': {e}")
        sys.exit(1)

def _build_exclusion_set(additional_excludes: list[str]) -> set[str]:
    """Builds the set of lowercased directory names to exclude."""
    all_excluded_dir_names_lower = {name.lower() for name in DEFAULT_EXCLUDED_DIR_NAMES}
    all_excluded_dir_names_lower.update(name.lower() for name in additional_excludes)
    logger.debug(f"Effective excluded directory names (case-insensitive): {sorted(list(all_excluded_dir_names_lower))}")
    return all_excluded_dir_names_lower

def _gather_files_to_process(source_dir: Path, args: argparse.Namespace, all_excluded_dir_names_lower: set[str]) -> list[tuple[Path, str]]:
    """Scans source directory, filters files, and returns a list of files to process."""
    logger.info(f"Scanning files in '{source_dir}'...")
    if args.verbose:
        exclusion_summary_parts = []
        if not args.include_dot_files:
            exclusion_summary_parts.append("Files starting with '.'")
        if not args.include_binary_files:
            exclusion_summary_parts.append("Files with binary extensions")
        if all_excluded_dir_names_lower:
            exclusion_summary_parts.append(f"Directory names like: {', '.join(sorted(list(all_excluded_dir_names_lower)))}")
        if exclusion_summary_parts:
            logger.debug(f"Exclusion criteria: {'; '.join(exclusion_summary_parts)}")
        else:
            logger.debug("No specific file/dir name exclusion criteria beyond path traversal rules.")

    files_to_process = []
    for item_path in source_dir.rglob('*'):
        if not item_path.is_file():
            logger.debug(f"Skipping non-file item: {item_path}")
            continue

        try:
            relative_path = item_path.relative_to(source_dir)
        except ValueError:
            logger.warning(f"File '{item_path}' seems outside source dir '{source_dir}'. Skipping.")
            continue
        
        should_exclude = False
        dir_parts_lower = [part.lower() for part in relative_path.parts[:-1]]

        for part_lower in dir_parts_lower:
            if part_lower in all_excluded_dir_names_lower:
                logger.debug(f"Excluding '{item_path}' (in excluded directory '{part_lower}')")
                should_exclude = True
                break
        if should_exclude: continue

        if not args.include_dot_files and item_path.name.startswith('.'):
            logger.debug(f"Excluding '{item_path}' (dot-file, --include-dot-files not set)")
            should_exclude = True
        if should_exclude: continue

        if not args.include_binary_files:
            extension = item_path.suffix.lower()
            if extension in BINARY_FILE_EXTENSIONS:
                logger.debug(f"Excluding '{item_path}' (binary extension '{extension}', --include-binary-files not set)")
                should_exclude = True
        if should_exclude: continue
        
        files_to_process.append((item_path, str(relative_path)))
    return files_to_process

def _write_combined_data(output_file_path: Path, files_to_process: list[tuple[Path, str]], args: argparse.Namespace, chosen_linesep: str) -> int:
    """Writes the combined file data to the output file and returns the count of processed files."""
    total_files = len(files_to_process)
    logger.info(f"Processing {total_files} file(s) for inclusion...")
    file_counter = 0
    try:
        with open(output_file_path, 'w', encoding='utf-8') as outfile:
            for file_info, rel_path_str in files_to_process:
                file_counter += 1
                logger.debug(f"Processing file ({file_counter}/{total_files}): {file_info.name} (Rel: {rel_path_str})")

                separator_text = get_file_separator(file_info, rel_path_str, args.separator_style, chosen_linesep)
                outfile.write(separator_text + chosen_linesep)

                if args.separator_style != 'Markdown':
                    outfile.write(chosen_linesep)

                content = "" # Initialize content to ensure it's defined for the 'finally' like block
                try:
                    content = file_info.read_text(encoding='utf-8', errors='ignore')
                    outfile.write(content)
                except Exception as e:
                    error_message = f"[ERROR: UNABLE TO READ FILE '{file_info}'. REASON: {e}]"
                    logger.warning(error_message)
                    outfile.write(error_message + chosen_linesep)
                
                # Ensure content block is followed by a newline if it didn't originally have one.
                # This makes sure the closing separator or next file's header starts on a new line.
                if content and not content.endswith(('\n', '\r')):
                    outfile.write(chosen_linesep)
                # If content was empty or already ended with a newline, this step is skipped.

                closing_separator_text = get_closing_separator(args.separator_style)
                if closing_separator_text:
                    outfile.write(closing_separator_text + chosen_linesep)
                
                if file_counter < total_files:
                    outfile.write(chosen_linesep)
        return file_counter
    except IOError as e:
        logger.error(f"An I/O error occurred writing to '{output_file_path}': {e}")
        sys.exit(1)
    except Exception as e:
        logger.error(f"An unexpected error occurred during file processing: {e}", exc_info=args.verbose)
        sys.exit(1)


# --- Main Script Logic ---

def main():
    """
    Main function to parse arguments and orchestrate the file combination process.
    """
    parser = argparse.ArgumentParser(
        description="Combines the content of multiple text files into a single output file, with metadata. \n"
                    "Useful for code reviews, documentation bundling, or sharing multiple files as one.",
        epilog="""Examples:
  %(prog)s --source-directory "./src" --output-file "combined_files.txt"
  %(prog)s -s "/home/user/projects/my_app" -o "/tmp/app_bundle.md" -t --separator-style Markdown --force
  %(prog)s -s . -o archive.txt --additional-excludes "docs_archive" "test_data" --include-dot-files --line-ending crlf
  %(prog)s -s ./config_files --include-dot-files --include-binary-files -o all_configs.txt --verbose""",
        formatter_class=argparse.RawTextHelpFormatter
    )

    parser.add_argument(
        '-s', '--source-directory',
        type=str,
        required=True,
        help="Path to the directory containing the files to be combined."
    )
    parser.add_argument(
        '-o', '--output-file',
        type=str,
        required=True,
        help="Path where the combined output file will be created."
    )
    parser.add_argument(
        '-f', '--force',
        action='store_true',
        help="Force overwrite of output file without prompting."
    )
    parser.add_argument(
        '-t', '--add-timestamp',
        action='store_true',
        help="Add a timestamp (_yyyyMMdd_HHmmss) to the output filename."
    )
    parser.add_argument(
        '--additional-excludes',
        type=str,
        nargs='*',
        default=[],
        metavar='DIR_NAME',
        help="Space-separated list of additional directory NAMES to exclude (e.g., 'obj', 'debug'). Case-insensitive."
    )
    parser.add_argument(
        '--include-dot-files',
        action='store_true',
        help="Include files that start with a dot (e.g., .gitignore). Dot directories (e.g. .git) are generally excluded by default_excluded_dir_names."
    )
    parser.add_argument(
        '--include-binary-files',
        action='store_true',
        help="Attempt to include files with binary extensions. Content may be unreadable. Use with caution."
    )
    parser.add_argument(
        '--separator-style',
        choices=['Standard', 'Detailed', 'Markdown'],
        default='Detailed',
        help="Format of the separator between files. Default: Detailed."
    )
    parser.add_argument(
        '--line-ending',
        choices=['lf', 'crlf'],
        default='lf',
        help="Line ending for script-generated separators/newlines. 'lf' (Unix) or 'crlf' (Windows). Default: lf. Does not change line endings of original file content."
    )
    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help="Enable verbose output (DEBUG level logging)."
    )

    args = parser.parse_args()

    chosen_linesep = LF if args.line_ending == 'lf' else CRLF
    _configure_logging_settings(args.verbose, chosen_linesep)

    source_dir = _resolve_and_validate_source_path(args.source_directory)
    output_file_path = _prepare_output_file_path(args.output_file, args.add_timestamp)

    _handle_output_file_overwrite_and_creation(output_file_path, args.force, chosen_linesep)

    all_excluded_dir_names_lower = _build_exclusion_set(args.additional_excludes)
    
    files_to_process = _gather_files_to_process(source_dir, args, all_excluded_dir_names_lower)

    if not files_to_process:
        logger.warning(f"No files found matching the criteria in '{source_dir}'.")
        try:
            with open(output_file_path, 'w', encoding='utf-8') as f:
                f.write(f"# No files processed from {source_dir}{chosen_linesep}")
            logger.info(f"Empty output file (with a note) created at '{output_file_path}'.")
        except Exception as e:
            logger.error(f"Could not create empty output file '{output_file_path}': {e}")
            sys.exit(1)
        sys.exit(0)

    processed_count = _write_combined_data(output_file_path, files_to_process, args, chosen_linesep)

    logger.info(f"Successfully combined {processed_count} file(s) into '{output_file_path}'.")
    sys.exit(0)


if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        # Print newline so the prompt isn't on the same line as ^C
        print(f"{LF}Operation cancelled by user.", file=sys.stderr)
        sys.exit(130) # Standard exit code for Ctrl+C
    except SystemExit as e:
        # Catch sys.exit() calls to ensure they propagate correctly
        sys.exit(e.code)
    except Exception as e:
        # Fallback for any unexpected errors not caught in main()
        logger.critical(f"An unexpected critical error occurred: {e}", exc_info=True)
        sys.exit(1)