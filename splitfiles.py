#!/usr/bin/env python3
"""
=========================
PySplitOneFile - File Splitter
=========================

SYNOPSIS
========
Splits a single input file (created by a tool like pymakeonefile.py) back into
multiple files, recreating the original directory structure within a specified
destination directory.

DESCRIPTION
===========
This script is the counterpart to file combiners. It reads a specially formatted
text file where multiple original files have been concatenated, each preceded by
a metadata separator. It parses these separators to determine the original
relative file paths and extracts the content for each file, saving them to the
destination directory.

It is designed to work with files generated by `pymakeonefile.py` and supports
its 'Standard', 'Detailed', and 'Markdown' separator styles.

KEY FEATURES
============
- Parses input files with 'Standard', 'Detailed', or 'Markdown' style separators.
- Recreates the original directory structure based on paths found in separators.
- Handles both LF and CRLF line endings in separator patterns and content processing.
- Option to force overwrite of existing files in the destination.
- Verbose mode for detailed operational logging.
- Secure path handling to prevent writing outside the destination directory.

REQUIREMENTS
============
- Python 3.7+ (due to `pathlib` usage and f-strings)
- Standard Python libraries only (argparse, logging, os, pathlib, re, sys).

USAGE
=====
Basic command:
  python splitfiles.py --input-file /path/to/combined_output.txt --destination-directory /path/to/output_folder

With force overwrite and verbose output:
  python splitfiles.py -i combined.txt -d ./extracted_files -f -v

For all options, run:
  python splitfiles.py --help

NOTES
=====
- Encoding: The script expects the input file to be UTF-8 encoded (matching
  `pymakeonefile.py`'s output) and writes extracted files as UTF-8.
- Line Endings: The script correctly identifies separators and content
  regardless of LF or CRLF line endings used in the input file. The content of
  the extracted files will retain the line endings as they were in the combined file.
- Separator Integrity: The script relies on the specific separator formats
  generated by `pymakeonefile.py`. Modified or corrupted separators might lead
  to incorrect parsing.

AUTHOR
======
Franz und Franz (Concept based on pymakeonefile.py)
AI (Python implementation)

VERSION
=======
1.0.0
"""

import argparse
import logging
import os
import re
import sys
from pathlib import Path

# --- Logger Setup ---
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO, format='%(levelname)-8s: %(message)s')

# --- Global Definitions ---
LF = '\n'
CRLF = '\r\n'

# Separator Regex Patterns
# These regexes are designed to match the beginning of a separator block
# and capture the relative file path. The order in `separator_patterns`
# in `parse_combined_file` is important (most specific first).
#
# Each regex aims to capture:
# Group 1: The entire separator header (used to determine header length).
# Group 2: The relative file path.

RE_DETAILED_SEP = re.compile(
    r"^(========================================================================================$\r?\n"  # Optional CR before LF
    r"== FILE: (.*?)$\r?\n"
    r"== DATE: .*? \| SIZE: .*? \| TYPE: .*?$\r?\n"
    r"========================================================================================$\r?\n?)" # Optional final newline
    , re.MULTILINE
)

RE_STANDARD_SEP = re.compile(
    r"^(======= (.*?) =======$\r?\n?)" # Optional final newline
    , re.MULTILINE
)

RE_MARKDOWN_SEP = re.compile(
    r"^(## (.*?)$\r?\n"
    r"\*\*Date Modified:\*\* .*? \| \*\*Size:\*\* .*? \| \*\*Type:\*\* .*?$\r?\n\r?\n" # Two newlines after metadata
    r"```(?:.*?)$\r?\n)" # Matches up to and including the opening ```[lang] and its newline
    , re.MULTILINE
)


# --- Helper Functions ---

def _configure_logging(verbose: bool):
    """Configures logging level based on verbosity."""
    if verbose:
        logging.getLogger().setLevel(logging.DEBUG)
        logger.debug("Verbose mode enabled.")

def _resolve_input_file(input_file_str: str) -> Path:
    """Resolves and validates the source input file path."""
    try:
        input_file = Path(input_file_str).resolve(strict=True)
        if not input_file.is_file():
            logger.error(f"Input path '{input_file}' is not a file.")
            sys.exit(1)
        return input_file
    except FileNotFoundError:
        logger.error(f"Input file '{input_file_str}' not found.")
        sys.exit(1)
    except Exception as e:
        logger.error(f"Error resolving input file '{input_file_str}': {e}")
        sys.exit(1)

def _prepare_destination_dir(dest_dir_str: str) -> Path:
    """Resolves the destination directory path and creates it if it doesn't exist."""
    dest_dir = Path(dest_dir_str).resolve()
    try:
        dest_dir.mkdir(parents=True, exist_ok=True)
        return dest_dir
    except Exception as e:
        logger.error(f"Could not create or access destination directory '{dest_dir}': {e}")
        sys.exit(1)

def parse_combined_file(content: str) -> list[dict]:
    """
    Parses the combined file content and extracts individual file data.
    The function identifies file separators using a list of regex patterns,
    sorts them by their appearance in the file, and then extracts
    the content between each separator and the next.

    Args:
        content: The entire string content of the combined input file.

    Returns:
        A list of dictionaries, where each dict contains:
        'path': relative_path_str
        'content': file_content_str
    """
    extracted_files = []

    # Order matters: More specific patterns (like Markdown with its ```) should come before general ones.
    separator_patterns = [
        {'id': 'Markdown', 'regex': RE_MARKDOWN_SEP, 'path_group': 2, 'header_group': 1},
        {'id': 'Detailed', 'regex': RE_DETAILED_SEP, 'path_group': 2, 'header_group': 1},
        {'id': 'Standard', 'regex': RE_STANDARD_SEP, 'path_group': 2, 'header_group': 1},
    ]

    matches = []
    for pattern_info in separator_patterns:
        for match in pattern_info['regex'].finditer(content):
            matches.append({
                'id': pattern_info['id'],
                'match_obj': match,
                'path': match.group(pattern_info['path_group']).strip(),
                'header_len': len(match.group(pattern_info['header_group'])),
                'start_index': match.start()
            })

    # Sort matches by their start index in the original content to process files in order.
    matches.sort(key=lambda m: m['start_index'])

    if not matches:
        logger.warning("No recognizable file separators found in the input file.")
        return []

    for i, current_match_info in enumerate(matches):
        sep_id = current_match_info['id']
        match_obj = current_match_info['match_obj']
        relative_path = current_match_info['path']
        
        content_start_pos = match_obj.end()

        next_separator_start_pos = len(content)
        if i + 1 < len(matches):
            next_separator_start_pos = matches[i+1]['start_index']

        file_content_raw = content[content_start_pos:next_separator_start_pos]
        file_content = ""

        if sep_id == 'Markdown':
            # makeonefile.py writes:
            #   NormalizedFileContent
            #   "```" (from get_closing_separator)
            #   chosen_linesep (after closing separator)
            #   chosen_linesep (inter-file, if applicable)
            # So, file_content_raw is NormalizedFileContent + "```" + linesep1 + [optional_linesep2]
            
            _processed_content = file_content_raw
            # Strip the optional inter-file newline separator (if this is not the last file segment).
            if i + 1 < len(matches):
                if _processed_content.endswith(CRLF):
                    _processed_content = _processed_content[:-len(CRLF)]
                elif _processed_content.endswith(LF):
                    _processed_content = _processed_content[:-len(LF)]
            
            # Strip the "```" + its own trailing newline (closing marker part).
            if _processed_content.endswith("```" + CRLF):
                file_content = _processed_content[:-(len("```" + CRLF))]
            elif _processed_content.endswith("```" + LF):
                file_content = _processed_content[:-(len("```" + LF))]
            else:
                logger.warning(
                    f"Markdown file '{relative_path}' closing sequence '```[newline]' "
                    f"not found as expected. Content might be incorrect."
                )
                file_content = file_content_raw # Fallback
        
        else: # Standard or Detailed
            # makeonefile.py writes:
            #   chosen_linesep (blank line after header)
            #   NormalizedFileContent
            #   chosen_linesep (inter-file, if applicable)
            # So, file_content_raw is: BlankLinesep_after_header + ActualFileContent + [optional_InterFileLinesep]

            _processed_content = file_content_raw
            
            # Strip the leading blank line (the first linesep written by makeonefile after the header for these styles).
            if _processed_content.startswith(CRLF):
                _processed_content = _processed_content[len(CRLF):]
            elif _processed_content.startswith(LF):
                _processed_content = _processed_content[len(LF):]
            
            # Strip the optional trailing inter-file newline separator (if this is not the last file segment).
            if i + 1 < len(matches):
                if _processed_content.endswith(CRLF):
                    _processed_content = _processed_content[:-len(CRLF)]
                elif _processed_content.endswith(LF):
                    _processed_content = _processed_content[:-len(LF)]
            
            file_content = _processed_content

        extracted_files.append({
            'path': relative_path,
            'content': file_content,
        })
        logger.debug(f"Identified file: '{relative_path}', type: {sep_id}, content length: {len(file_content)}")

    return extracted_files


def _write_extracted_files(
    dest_dir_path: Path,
    extracted_files_data: list[dict],
    force_overwrite: bool
) -> tuple[int, int, int]:
    """
    Writes the extracted file data to the destination directory.

    Args:
        dest_dir_path: The root directory where files will be written.
        extracted_files_data: A list of dictionaries, each containing the
                              relative path and content for a file.
        force_overwrite: Boolean indicating whether to overwrite existing files
                         without prompting.

    Returns:
        A tuple containing (files_created_count, files_overwritten_count, files_failed_count).
    """
    files_created_count = 0
    files_overwritten_count = 0
    files_failed_count = 0

    logger.info(f"Writing {len(extracted_files_data)} extracted file(s) to '{dest_dir_path}'...")
    for file_data in extracted_files_data:
        relative_path_str = file_data['path']
        file_content_to_write = file_data['content']
        
        # Security check: ensure relative paths do not try to escape the destination directory.
        if ".." in Path(relative_path_str).parts:
            logger.error(f"Skipping file '{relative_path_str}' due to invalid path components ('..').")
            files_failed_count +=1
            continue

        current_output_path = dest_dir_path / relative_path_str

        logger.debug(f"Preparing to write: {current_output_path}")

        try:
            # Ensure parent directory exists.
            current_output_path.parent.mkdir(parents=True, exist_ok=True)
            
            if current_output_path.exists() and not force_overwrite:
                try:
                    confirmation = input(f"Output file '{current_output_path}' already exists. Overwrite? (y/N): ")
                    if confirmation.lower() != 'y':
                        logger.info(f"Skipping existing file '{current_output_path}'.")
                        continue
                except KeyboardInterrupt: # Handle Ctrl+C during prompt
                    logger.info(f"{(LF if os.name != 'nt' else CRLF)}Operation cancelled by user (Ctrl+C).")
                    sys.exit(0) # Graceful exit as user initiated stop before action

            is_overwrite = current_output_path.exists()
            current_output_path.write_text(file_content_to_write, encoding='utf-8')
            
            if is_overwrite:
                files_overwritten_count += 1
                logger.debug(f"Overwrote file: {current_output_path}")
            else:
                files_created_count += 1
                logger.debug(f"Created file: {current_output_path}")

        except Exception as e:
            logger.error(f"Failed to write file '{current_output_path}': {e}")
            files_failed_count +=1
    
    return files_created_count, files_overwritten_count, files_failed_count

def main():
    """
    Parses command-line arguments and orchestrates the file splitting process.
    It reads the combined input file, parses it to extract individual file data,
    and then writes these files to the specified destination directory.
    """
    parser = argparse.ArgumentParser(
        description="Splits a combined file (from pymakeonefile.py) back into individual files.",
        epilog="Example: %(prog)s -i combined.txt -d ./output_src --force",
        formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument(
        '-i', '--input-file',
        type=str,
        required=True,
        help="Path to the combined input file."
    )
    parser.add_argument(
        '-d', '--destination-directory',
        type=str,
        required=True,
        help="Directory where extracted files will be saved."
    )
    parser.add_argument(
        '-f', '--force',
        action='store_true',
        help="Force overwrite of existing files in the destination directory without prompting."
    )
    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help="Enable verbose output (DEBUG level logging)."
    )

    args = parser.parse_args()
    _configure_logging(args.verbose)

    input_file_path = _resolve_input_file(args.input_file)
    dest_dir_path = _prepare_destination_dir(args.destination_directory)

    logger.info(f"Reading input file: {input_file_path}")
    try:
        combined_content = input_file_path.read_text(encoding='utf-8')
    except Exception as e:
        logger.error(f"Failed to read input file '{input_file_path}': {e}")
        sys.exit(1)

    logger.info("Parsing combined file content...")
    extracted_files_data = parse_combined_file(combined_content)

    if not extracted_files_data:
        logger.info("No files extracted. Output directory will be empty or unchanged.")
        sys.exit(0)

    files_created_count, files_overwritten_count, files_failed_count = _write_extracted_files(
        dest_dir_path, extracted_files_data, args.force
    )

    logger.info("File splitting process completed.")
    logger.info(f"Files created: {files_created_count}")
    logger.info(f"Files overwritten (with --force or confirmation): {files_overwritten_count}")
    if files_failed_count > 0:
        logger.warning(f"Files failed to write: {files_failed_count}")
    
    if files_failed_count > 0:
        sys.exit(1)
    sys.exit(0)


if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        # Ensure newline after ^C
        print(f"{(LF if os.name != 'nt' else CRLF)}Operation cancelled by user.", file=sys.stderr)
        sys.exit(130) # Standard exit code for Ctrl+C
    except SystemExit as e:
        # Catch sys.exit() calls to ensure they propagate correctly
        sys.exit(e.code)
    except Exception as e:
        # Fallback for any unexpected errors not caught in main()
        logger.critical(f"An unexpected critical error occurred: {e}", exc_info=True)
        sys.exit(1) 